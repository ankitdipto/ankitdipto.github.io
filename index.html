<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Jon Barron</title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Ankit Sinha</name>
              </p>
              <p>Currently, I am a Member of Technical Staff with <a href="https://ai.google/research">Google Research</a>, where I work on computer vision and machine learning.
              </p>
              <p>
                At Google I've worked on <a href="https://www.google.com/glass/start/">Glass</a>,  <a href="https://ai.googleblog.com/2014/04/lens-blur-in-new-google-camera-app.html">Lens Blur</a>, <a href="https://ai.googleblog.com/2014/10/hdr-low-light-and-high-dynamic-range.html">HDR+</a>, <a href="https://blog.google/products/google-ar-vr/introducing-next-generation-jump/">Jump</a>, <a href="https://ai.googleblog.com/2017/10/portrait-mode-on-pixel-2-and-pixel-2-xl.html">Portrait Mode</a>, <a href="https://ai.googleblog.com/2020/12/portrait-light-enhancing-portrait.html">Portrait Light</a>, and <a href="https://www.matthewtancik.com/nerf">NeRF</a>. I did my PhD at <a href="http://www.eecs.berkeley.edu/">UC Berkeley</a>, where I was advised by <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a> and funded by the <a href="http://www.nsfgrfp.org/">NSF GRFP</a>. I've received the <a href="https://www2.eecs.berkeley.edu/Students/Awards/15/">C.V. Ramamoorthy Distinguished Research Award</a> and the <a href="https://www.thecvf.com/?page_id=413#YRA">PAMI Young Researcher Award</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:jonbarron@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/JonBarron-CV.pdf">CV</a> &nbsp/&nbsp
                <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=jktWnL8AAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/jonbarron/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/JonBarron.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/JonBarron_circle.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in computer vision, machine learning, optimization, and image processing. Much of my research is about inferring the physical world (shape, motion, color, light, etc) from images. Representative papers are <span class="highlight">highlighted</span>.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="malle_stop()" onmouseover="malle_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='malle_image'>
                  <img src='images/MalleConv_after.jpg' width="160"></div>
                <img src='images/MalleConv_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function malle_start() {
                  document.getElementById('malle_image').style.opacity = "1";
                }

                function malle_stop() {
                  document.getElementById('malle_image').style.opacity = "0";
                }
                malle_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://yifanjiang.net/MalleConv.html">
                <papertitle>Fast and High-quality Image Denoising via Malleable Convolutions</papertitle>
              </a>
              <br>
              <a href="https://yifanjiang.net/">Yifan Jiang</a>,
              <a href="https://bartwronski.com/">Bartlomiej Wronski</a>, 
							<a href="https://bmild.github.io/">Ben Mildenhall</a>, <br>
              <strong>Jonathan T. Barron</strong>,
              <a href="https://spark.adobe.com/page/CAdrFMJ9QeI2y/">Zhangyang Wang</a>,
              <a href="https://people.csail.mit.edu/tfxue/">Tianfan Xue</a>
              <br>
              <em>ECCV</em>, 2022
              <br>
              <a href="https://yifanjiang.net/MalleConv.html">project page</a>
              /
              <a href="https://arxiv.org/abs/2201.00392">arXiv</a>
              <p></p>
              <p>
              We denoise images efficiently by predicting spatially-varying kernels at low resolution and using a fast fused op to jointly upsample and apply these kernels at full resolution.
              </p>
            </td>
          </tr>

          <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerfbake_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/nerfbake_15.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/nerfbake_160.png' width="160">
              </div>
              <script type="text/javascript">
                function nerfbake_start() {
                  document.getElementById('nerfbake_image').style.opacity = "1";
                }

                function nerfbake_stop() {
                  document.getElementById('nerfbake_image').style.opacity = "0";
                }
                nerfbake_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://nerf.live">
              <papertitle>Baking Neural Radiance Fields for Real-Time View Synthesis</papertitle>
              </a>
              <br>
              <a href="https://phogzone.com/">Peter Hedman</a>,
              <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
              <a href="https://bmild.github.io/">Ben Mildenhall</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="https://www.pauldebevec.com/">Paul Debevec</a>
              <br>
							<em>ICCV</em>, 2021 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="http://nerf.live">project page</a>
              /
              <a href="https://arxiv.org/abs/2103.14645">arXiv</a>
              /
              <a href="https://www.youtube.com/watch?v=5jKry8n5YO8">video</a>
              /
              <a href="https://nerf.live/#demos">demo</a>
              <p></p>
              <p>Baking a trained NeRF into a sparse voxel grid of colors and features lets you render it in real-time in your browser.</p>
            </td>
          </tr>


          
          <tr onmouseout="dt_stop()" onmouseover="dt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='dt_image'><img src='images/DT_edge.jpg'></div>
                <img src='images/DT_image.jpg'>
              </div>
              <script type="text/javascript">
                function dt_start() {
                  document.getElementById('dt_image').style.opacity = "1";
                }

                function dt_stop() {
                  document.getElementById('dt_image').style.opacity = "0";
                }
                dt_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/178Xj2PZ1w6hZJpucU-TiZOoCemJmvsVQ/view?usp=sharing">
                <papertitle>Semantic Image Segmentation with Task-Specific Edge Detection Using CNNs and a Discriminatively Trained Domain Transform</papertitle>
              </a>
              <br>
              <em>CVPR</em>, 2016
              <br>
              <a href="http://liangchiehchen.com/">Liang-Chieh Chen</a>, <strong>Jonathan T. Barron</strong>, <a href="http://ttic.uchicago.edu/~gpapan/">George Papandreou</a>, <a href="http://www.cs.ubc.ca/~murphyk/">Kevin Murphy</a>, <a href="http://www.stat.ucla.edu/~yuille/">Alan L. Yuille</a>
              <br>
              <a href="data/Chen2016.bib">bibtex</a> /
              <a href="http://liangchiehchen.com/projects/DeepLab.html">project page</a> /
              <a href="https://bitbucket.org/aquariusjay/deeplab-public-ver2">code</a>
              <p></p>
              <p>By integrating an edge-aware filter into a convolutional neural network we can learn an edge-detector while improving semantic segmentation.</p>
            </td>
          </tr>

          <tr onmouseout="ccc_stop()" onmouseover="ccc_start()" bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ccc_image'><img src='images/ccc_after.jpg'></div>
                <img src='images/ccc_before.jpg'>
              </div>
              <script type="text/javascript">
                function ccc_start() {
                  document.getElementById('ccc_image').style.opacity = "1";
                }

                function ccc_stop() {
                  document.getElementById('ccc_image').style.opacity = "0";
                }
                ccc_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1id74VNDL8ACrrWf6vYgN2M4kS8gd4n7w/view?usp=sharing">
                <papertitle>Convolutional Color Constancy</papertitle>
              </a>
              <br>
              <strong>Jonathan T. Barron</strong>
              <br>
              <em>ICCV</em>, 2015
              <br>
              <a href="https://drive.google.com/file/d/1vO3sVOMihmpNqsuASeR46Y_iME0lOANR/view?usp=sharing">supplement</a> / <a href="data/BarronICCV2015.bib">bibtex</a> / <a href="https://youtu.be/saHwKY9rfx0">video</a> (or <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmalBNUzlENUJSVDg/view?usp=sharing">mp4</a>)
              <p></p>
              <p>By framing white balance as a chroma localization task we can discriminatively learn a color constancy model that beats the state-of-the-art by 40%.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/Shelhamer2015.jpg'>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1stygV71uBruD7Ck9CaAQr7nREvr3DtUL/view?usp=sharing">
                <papertitle>Scene Intrinsics and Depth from a Single Image</papertitle>
              </a>
              <br>
              <a href="http://imaginarynumber.net/">Evan Shelhamer</a>, <strong>Jonathan T. Barron</strong>, <a href="http://www.eecs.berkeley.edu/%7Etrevor/">Trevor Darrell</a>
              <br>
              <em>ICCV Workshop</em>, 2015
              <br>
              <a href="data/Shelhamer2015.bib">bibtex</a>
              <p></p>
              <p>The monocular depth estimates produced by fully convolutional networks can be used to inform intrinsic image estimation.</p>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/clean_promo.jpg" alt="clean-usnob" width="160" height="160">
            </td>
            <td width="75%" valign="middle">
              <a href="https://drive.google.com/file/d/1YvRx-4hrZoCk-nl6OgVJZlHAqOiN5hWq/view?usp=sharing">
                <papertitle>Cleaning the USNO-B Catalog Through Automatic Detection of Optical Artifacts</papertitle>
              </a>
              <br>
              <strong>Jonathan T. Barron</strong>, <a href="http://stumm.ca/">Christopher Stumm</a>, <a href="http://cosmo.nyu.edu/hogg/">David W. Hogg</a>, <a href="http://www.astro.princeton.edu/~dstn/">Dustin Lang</a>, <a href="http://cs.nyu.edu/~roweis/">Sam Roweis</a>
              <br>
              <em>The Astronomical Journal</em>, 135, 2008
              <p>We use computer vision techniques to identify and remove diffraction spikes and reflection halos in the USNO-B Catalog.</p>
              <p>In use at <a href="http://www.astrometry.net">Astrometry.net</a></p>
            </td>
          </tr>

        </tbody></table>

				
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Misc</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
					
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
            <td width="75%" valign="center">
              <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
              <br>
              <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Longuet-Higgins Award Committee Member, CVPR 2021</a>
              <br>
              <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
              <br>
              <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cs188.jpg" alt="cs188">
            </td>
            <td width="75%" valign="center">
              <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
              <br>
              <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
              <br>
              <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
            </td>
          </tr>
					

          <tr>
            <td align="center" style="padding:20px;width:25%;vertical-align:middle">
							<heading>Basically <br> Blog Posts</heading>
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
              <br>
              <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
              <br>
              <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
            </td>
          </tr>
					
					
        </tbody></table>
        
</body>

</html>
